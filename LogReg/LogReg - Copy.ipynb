{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import statements\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store data\n",
    "testData = pd.read_csv(r'testDataClean.csv', low_memory=False)\n",
    "trainData = pd.read_csv(r'trainDataClean.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.10</th>\n",
       "      <th>FLUX.12</th>\n",
       "      <th>FLUX.14</th>\n",
       "      <th>FLUX.16</th>\n",
       "      <th>FLUX.18</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3178</th>\n",
       "      <th>FLUX.3180</th>\n",
       "      <th>FLUX.3182</th>\n",
       "      <th>FLUX.3184</th>\n",
       "      <th>FLUX.3186</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3196</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>83.81</td>\n",
       "      <td>-26.98</td>\n",
       "      <td>-124.71</td>\n",
       "      <td>-96.27</td>\n",
       "      <td>-160.17</td>\n",
       "      <td>-154.88</td>\n",
       "      <td>-146.56</td>\n",
       "      <td>-102.85</td>\n",
       "      <td>-48.42</td>\n",
       "      <td>...</td>\n",
       "      <td>-193.16</td>\n",
       "      <td>-17.56</td>\n",
       "      <td>125.62</td>\n",
       "      <td>100.01</td>\n",
       "      <td>-25.39</td>\n",
       "      <td>-78.07</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>48.57</td>\n",
       "      <td>39.32</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.83</td>\n",
       "      <td>-40.09</td>\n",
       "      <td>-72.81</td>\n",
       "      <td>-85.33</td>\n",
       "      <td>-73.38</td>\n",
       "      <td>-74.97</td>\n",
       "      <td>-86.13</td>\n",
       "      <td>-61.27</td>\n",
       "      <td>-48.53</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.53</td>\n",
       "      <td>-23.88</td>\n",
       "      <td>-9.03</td>\n",
       "      <td>11.61</td>\n",
       "      <td>-5.69</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>-11.70</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>535.92</td>\n",
       "      <td>496.92</td>\n",
       "      <td>466.00</td>\n",
       "      <td>486.39</td>\n",
       "      <td>484.39</td>\n",
       "      <td>462.30</td>\n",
       "      <td>441.20</td>\n",
       "      <td>481.28</td>\n",
       "      <td>554.34</td>\n",
       "      <td>...</td>\n",
       "      <td>14.00</td>\n",
       "      <td>-34.98</td>\n",
       "      <td>-17.06</td>\n",
       "      <td>7.86</td>\n",
       "      <td>-64.44</td>\n",
       "      <td>-71.69</td>\n",
       "      <td>13.31</td>\n",
       "      <td>-20.88</td>\n",
       "      <td>-11.80</td>\n",
       "      <td>-70.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>347.39</td>\n",
       "      <td>298.13</td>\n",
       "      <td>312.70</td>\n",
       "      <td>311.31</td>\n",
       "      <td>323.33</td>\n",
       "      <td>326.19</td>\n",
       "      <td>313.89</td>\n",
       "      <td>330.92</td>\n",
       "      <td>360.58</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.12</td>\n",
       "      <td>6.63</td>\n",
       "      <td>-8.57</td>\n",
       "      <td>-21.90</td>\n",
       "      <td>-29.86</td>\n",
       "      <td>5.71</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>20.03</td>\n",
       "      <td>-8.77</td>\n",
       "      <td>-17.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1112.59</td>\n",
       "      <td>-1095.10</td>\n",
       "      <td>-1034.48</td>\n",
       "      <td>-1022.71</td>\n",
       "      <td>-970.88</td>\n",
       "      <td>-889.49</td>\n",
       "      <td>-853.95</td>\n",
       "      <td>-754.48</td>\n",
       "      <td>-649.34</td>\n",
       "      <td>...</td>\n",
       "      <td>-672.71</td>\n",
       "      <td>-597.60</td>\n",
       "      <td>-501.95</td>\n",
       "      <td>-468.59</td>\n",
       "      <td>-504.70</td>\n",
       "      <td>-594.37</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-443.76</td>\n",
       "      <td>-399.71</td>\n",
       "      <td>-411.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1599 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL   FLUX.2   FLUX.4   FLUX.6   FLUX.8  FLUX.10  FLUX.12  FLUX.14  \\\n",
       "0      1    83.81   -26.98  -124.71   -96.27  -160.17  -154.88  -146.56   \n",
       "1      1   -33.83   -40.09   -72.81   -85.33   -73.38   -74.97   -86.13   \n",
       "2      1   535.92   496.92   466.00   486.39   484.39   462.30   441.20   \n",
       "3      1   347.39   298.13   312.70   311.31   323.33   326.19   313.89   \n",
       "4      1 -1112.59 -1095.10 -1034.48 -1022.71  -970.88  -889.49  -853.95   \n",
       "\n",
       "   FLUX.16  FLUX.18  ...  FLUX.3178  FLUX.3180  FLUX.3182  FLUX.3184  \\\n",
       "0  -102.85   -48.42  ...    -193.16     -17.56     125.62     100.01   \n",
       "1   -61.27   -48.53  ...     -19.53     -23.88      -9.03      11.61   \n",
       "2   481.28   554.34  ...      14.00     -34.98     -17.06       7.86   \n",
       "3   330.92   360.58  ...     -36.12       6.63      -8.57     -21.90   \n",
       "4  -754.48  -649.34  ...    -672.71    -597.60    -501.95    -468.59   \n",
       "\n",
       "   FLUX.3186  FLUX.3188  FLUX.3190  FLUX.3192  FLUX.3194  FLUX.3196  \n",
       "0     -25.39     -78.07    -102.15      48.57      39.32       5.08  \n",
       "1      -5.69      -3.28     -32.21      -4.86     -11.70      16.00  \n",
       "2     -64.44     -71.69      13.31     -20.88     -11.80     -70.02  \n",
       "3     -29.86       5.71      -3.73      20.03      -8.77     -17.35  \n",
       "4    -504.70    -594.37    -401.66    -443.76    -399.71    -411.79  \n",
       "\n",
       "[5 rows x 1599 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualization\n",
    "testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.10</th>\n",
       "      <th>FLUX.12</th>\n",
       "      <th>FLUX.14</th>\n",
       "      <th>FLUX.16</th>\n",
       "      <th>FLUX.18</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3178</th>\n",
       "      <th>FLUX.3180</th>\n",
       "      <th>FLUX.3182</th>\n",
       "      <th>FLUX.3184</th>\n",
       "      <th>FLUX.3186</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3196</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>83.81</td>\n",
       "      <td>-26.98</td>\n",
       "      <td>-124.71</td>\n",
       "      <td>-96.27</td>\n",
       "      <td>-160.17</td>\n",
       "      <td>-154.88</td>\n",
       "      <td>-146.56</td>\n",
       "      <td>-102.85</td>\n",
       "      <td>-48.42</td>\n",
       "      <td>...</td>\n",
       "      <td>-193.16</td>\n",
       "      <td>-17.56</td>\n",
       "      <td>125.62</td>\n",
       "      <td>100.01</td>\n",
       "      <td>-25.39</td>\n",
       "      <td>-78.07</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>48.57</td>\n",
       "      <td>39.32</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-33.83</td>\n",
       "      <td>-40.09</td>\n",
       "      <td>-72.81</td>\n",
       "      <td>-85.33</td>\n",
       "      <td>-73.38</td>\n",
       "      <td>-74.97</td>\n",
       "      <td>-86.13</td>\n",
       "      <td>-61.27</td>\n",
       "      <td>-48.53</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.53</td>\n",
       "      <td>-23.88</td>\n",
       "      <td>-9.03</td>\n",
       "      <td>11.61</td>\n",
       "      <td>-5.69</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>-11.70</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>535.92</td>\n",
       "      <td>496.92</td>\n",
       "      <td>466.00</td>\n",
       "      <td>486.39</td>\n",
       "      <td>484.39</td>\n",
       "      <td>462.30</td>\n",
       "      <td>441.20</td>\n",
       "      <td>481.28</td>\n",
       "      <td>554.34</td>\n",
       "      <td>...</td>\n",
       "      <td>14.00</td>\n",
       "      <td>-34.98</td>\n",
       "      <td>-17.06</td>\n",
       "      <td>7.86</td>\n",
       "      <td>-64.44</td>\n",
       "      <td>-71.69</td>\n",
       "      <td>13.31</td>\n",
       "      <td>-20.88</td>\n",
       "      <td>-11.80</td>\n",
       "      <td>-70.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>347.39</td>\n",
       "      <td>298.13</td>\n",
       "      <td>312.70</td>\n",
       "      <td>311.31</td>\n",
       "      <td>323.33</td>\n",
       "      <td>326.19</td>\n",
       "      <td>313.89</td>\n",
       "      <td>330.92</td>\n",
       "      <td>360.58</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.12</td>\n",
       "      <td>6.63</td>\n",
       "      <td>-8.57</td>\n",
       "      <td>-21.90</td>\n",
       "      <td>-29.86</td>\n",
       "      <td>5.71</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>20.03</td>\n",
       "      <td>-8.77</td>\n",
       "      <td>-17.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1112.59</td>\n",
       "      <td>-1095.10</td>\n",
       "      <td>-1034.48</td>\n",
       "      <td>-1022.71</td>\n",
       "      <td>-970.88</td>\n",
       "      <td>-889.49</td>\n",
       "      <td>-853.95</td>\n",
       "      <td>-754.48</td>\n",
       "      <td>-649.34</td>\n",
       "      <td>...</td>\n",
       "      <td>-672.71</td>\n",
       "      <td>-597.60</td>\n",
       "      <td>-501.95</td>\n",
       "      <td>-468.59</td>\n",
       "      <td>-504.70</td>\n",
       "      <td>-594.37</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-443.76</td>\n",
       "      <td>-399.71</td>\n",
       "      <td>-411.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1599 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL   FLUX.2   FLUX.4   FLUX.6   FLUX.8  FLUX.10  FLUX.12  FLUX.14  \\\n",
       "0      1    83.81   -26.98  -124.71   -96.27  -160.17  -154.88  -146.56   \n",
       "1      1   -33.83   -40.09   -72.81   -85.33   -73.38   -74.97   -86.13   \n",
       "2      1   535.92   496.92   466.00   486.39   484.39   462.30   441.20   \n",
       "3      1   347.39   298.13   312.70   311.31   323.33   326.19   313.89   \n",
       "4      1 -1112.59 -1095.10 -1034.48 -1022.71  -970.88  -889.49  -853.95   \n",
       "\n",
       "   FLUX.16  FLUX.18  ...  FLUX.3178  FLUX.3180  FLUX.3182  FLUX.3184  \\\n",
       "0  -102.85   -48.42  ...    -193.16     -17.56     125.62     100.01   \n",
       "1   -61.27   -48.53  ...     -19.53     -23.88      -9.03      11.61   \n",
       "2   481.28   554.34  ...      14.00     -34.98     -17.06       7.86   \n",
       "3   330.92   360.58  ...     -36.12       6.63      -8.57     -21.90   \n",
       "4  -754.48  -649.34  ...    -672.71    -597.60    -501.95    -468.59   \n",
       "\n",
       "   FLUX.3186  FLUX.3188  FLUX.3190  FLUX.3192  FLUX.3194  FLUX.3196  \n",
       "0     -25.39     -78.07    -102.15      48.57      39.32       5.08  \n",
       "1      -5.69      -3.28     -32.21      -4.86     -11.70      16.00  \n",
       "2     -64.44     -71.69      13.31     -20.88     -11.80     -70.02  \n",
       "3     -29.86       5.71      -3.73      20.03      -8.77     -17.35  \n",
       "4    -504.70    -594.37    -401.66    -443.76    -399.71    -411.79  \n",
       "\n",
       "[5 rows x 1599 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate x and y values of df\n",
    "y_train = trainData['LABEL']\n",
    "y_test = testData['LABEL']\n",
    "x_train = trainData.drop(['LABEL'], 1)\n",
    "x_test = testData.drop(['LABEL'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale input data\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create and fit LogReg object\n",
    "lg = LogisticRegression(max_iter=10000)\n",
    "lg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9931197169254964\n",
      "[[5050    0]\n",
      " [  35    2]]\n"
     ]
    }
   ],
   "source": [
    "#View model accuracy on training data\n",
    "train_pred = lg.predict(x_train)\n",
    "cm_train = confusion_matrix(y_train, train_pred)\n",
    "print(\"Accuracy : \", accuracy_score(y_train, train_pred))\n",
    "print(cm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict values\n",
    "y_pred = lg.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.987719298245614\n",
      "[[563   2]\n",
      " [  5   0]]\n"
     ]
    }
   ],
   "source": [
    "#View model accuracy on test data\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy : \", accuracy_score(y_test, y_pred))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb748cf4ed0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Confusion matrix visualized on a heatmap\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try same excercise but with statsmodel\n",
    "#import statsmodels.api as sm\n",
    "#x_train_sm = sm.add_constant(x_train)\n",
    "#temp = sm.GLM(y_train, x_train_sm, family = sm.families.Binomial())\n",
    "#lg2 = temp.fit()\n",
    "#pred_2 = lg2.predict(sm.add_constant(x_test))\n",
    "#cm_2 = confusion_matrix(y_test, pred_2)\n",
    "#print(\"Accuracy : \", accuracy_score(y_test, pred_2))\n",
    "#print(cm_2)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
